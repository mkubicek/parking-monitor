{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkubicek/repos/charging-station-monitor/.env/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:18: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/mkubicek/repos/charging-station-monitor/.env/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Rescaling, RandomRotation, RandomZoom, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from pathlib import Path\n",
    "\n",
    "def get_new_model(width, height):\n",
    "    model = Sequential([\n",
    "        # Preprocessing layers\n",
    "        Rescaling(1./255, input_shape=(width, height, 1)),\n",
    "        # Convolutional layers\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool1'),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool2'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool3'),\n",
    "        Flatten(name='flatten'),\n",
    "        Dense(128, activation='relu', name='dense1'),\n",
    "        Dropout(0.5, name='dropout'),\n",
    "        Dense(2, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model = get_new_model(256, 256)\n",
    "model.load_weights('v1.h5_2000.weights.h5')\n",
    "\n",
    "def get_class_name_from_path(path):\n",
    "    if 'empty' in str(path):\n",
    "        return 'empty'\n",
    "    if 'occupied' in str(path):\n",
    "        return 'occupied'\n",
    "    raise Exception('Unknown class')\n",
    "\n",
    "def get_class_name_from_index(index):\n",
    "    if index == 0:\n",
    "        return 'empty'\n",
    "    if index == 1:\n",
    "        return 'occupied'\n",
    "    raise Exception('Unknown class')\n",
    "\n",
    "def prepare_and_predict(image_path, model, target_size=(256, 256)):\n",
    "    img = load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = get_class_name_from_index(np.argmax(prediction, axis=1)[0])\n",
    "    true_class = get_class_name_from_path(image_path)\n",
    "    return image_path, true_class, predicted_class, prediction[0][0], prediction[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "image_paths = Path('./data_training/validation/').rglob('*.jpg')\n",
    "\n",
    "predictions = [prepare_and_predict(image_path, model) for image_path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns=['image_path', 'true_class', 'predicted_class', 'empty_prediction', 'occupied_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wrong predictions: 3.60%\n"
     ]
    }
   ],
   "source": [
    "wrong_predictions_count = (predictions_df['true_class'] != predictions_df['predicted_class']).sum()\n",
    "total_predictions = len(predictions_df)\n",
    "percentage_wrong_predictions = (wrong_predictions_count / total_predictions) * 100\n",
    "print(f\"Percentage of wrong predictions: {percentage_wrong_predictions:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 'empty' predictions that were wrong: 16.36%\n",
      "Percentage of 'occupied' predictions that were wrong: 0.06%\n"
     ]
    }
   ],
   "source": [
    "wrong_empty_predictions = predictions_df[\n",
    "    (predictions_df['true_class'] == 'empty') & (predictions_df['predicted_class'] != 'empty')\n",
    "]\n",
    "\n",
    "wrong_occupied_predictions = predictions_df[\n",
    "    (predictions_df['true_class'] == 'occupied') & (predictions_df['predicted_class'] != 'occupied')\n",
    "]\n",
    "\n",
    "total_empty_predictions = predictions_df[predictions_df['true_class'] == 'empty'].shape[0]\n",
    "total_occupied_predictions = predictions_df[predictions_df['true_class'] == 'occupied'].shape[0]\n",
    "\n",
    "percentage_wrong_empty = (len(wrong_empty_predictions) / total_empty_predictions * 100) if total_empty_predictions > 0 else 0\n",
    "percentage_wrong_occupied = (len(wrong_occupied_predictions) / total_occupied_predictions * 100) if total_occupied_predictions > 0 else 0\n",
    "\n",
    "print(f\"Percentage of 'empty' predictions that were wrong: {percentage_wrong_empty:.2f}%\")\n",
    "print(f\"Percentage of 'occupied' predictions that were wrong: {percentage_wrong_occupied:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set empty:  1667\n",
      "Training set occupied:  1666\n",
      "Validation set empty:  874\n",
      "Validation set occupied:  3152\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set empty:  \" + str(len(list(Path('./data_training/training/empty').rglob('*.jpg')))))\n",
    "print(\"Training set occupied:  \" + str(len(list(Path('./data_training/training/occupied').rglob('*.jpg')))))\n",
    "print(\"Validation set empty:  \" + str(len(list(Path('./data_training/validation/empty').rglob('*.jpg')))))\n",
    "print(\"Validation set occupied:  \" + str(len(list(Path('./data_training/validation/occupied').rglob('*.jpg')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "import random\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.utils import normalize\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_new_model(width, height):\n",
    "    inputs = Input(shape=(width, height, 1))\n",
    "    x = Rescaling(1./255.0)(inputs)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='maxpool1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='maxpool2')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='maxpool3')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(128, activation='relu', name='dense1')(x)\n",
    "    x = Dropout(0.5, name='dropout')(x)\n",
    "    outputs = Dense(2, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_new_model(256, 256)\n",
    "model.load_weights('v1.h5_2000.weights.h5')\n",
    "\n",
    "model_modifier = ReplaceToLinear()\n",
    "gradcam = Gradcam(model, model_modifier=model_modifier, clone=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show grad-cam heatmap of empty but incorrectly predicted\n",
    "def loss(output):\n",
    "    return output[:, 0]\n",
    "\n",
    "correct_predictions_df = predictions_df[('empty' == predictions_df['true_class']) & (predictions_df['true_class'] != predictions_df['predicted_class'])]\n",
    "selected_images = correct_predictions_df.sample(n=16, random_state=42)['image_path'].tolist()\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, image_path in enumerate(selected_images):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "    img_array = np.array(img) / 1.0\n",
    "    img_array = img_array[:, :, np.newaxis]\n",
    "\n",
    "    heatmap = gradcam(loss, img_array[np.newaxis, ...], penultimate_layer='conv3', expand_cam=True)\n",
    "    heatmap = normalize(heatmap)\n",
    "    heatmap_resized = cv2.resize(heatmap[0], (256, 256))\n",
    "\n",
    "    axs[idx].imshow(img_array.squeeze(), cmap='gray')\n",
    "    axs[idx].imshow(heatmap_resized, cmap='jet', alpha=0.5)\n",
    "    axs[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show grad-cam heatmap of occupied but incorrectly predicted \n",
    "def loss(output):\n",
    "    return output[:, 1]\n",
    "\n",
    "correct_predictions_df = predictions_df[('occupied' == predictions_df['true_class']) & (predictions_df['true_class'] != predictions_df['predicted_class'])]\n",
    "num_samples = 16\n",
    "if len(correct_predictions_df) >= num_samples:\n",
    "    random_correct_predictions = correct_predictions_df.sample(n=num_samples, random_state=42)\n",
    "else:\n",
    "    random_correct_predictions = correct_predictions_df.sample(n=min(num_samples, len(correct_predictions_df)), replace=True, random_state=42)\n",
    "\n",
    "selected_images = random_correct_predictions['image_path'].tolist()\n",
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, image_path in enumerate(selected_images):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "    img_array = np.array(img) / 1.0\n",
    "    img_array = img_array[:, :, np.newaxis]\n",
    "\n",
    "    heatmap = gradcam(loss, img_array[np.newaxis, ...], penultimate_layer='conv3', expand_cam=True)\n",
    "    heatmap = normalize(heatmap)\n",
    "    heatmap_resized = cv2.resize(heatmap[0], (256, 256))\n",
    "\n",
    "    axs[idx].imshow(img_array.squeeze(), cmap='gray')\n",
    "    axs[idx].imshow(heatmap_resized, cmap='jet', alpha=0.5)\n",
    "    axs[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data_training/validation/occupied/2023-08-26-200101.jpg'),\n",
       " PosixPath('data_training/validation/occupied/2023-08-07-182201.jpg')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions_df['image_path'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
