{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import RandomRotation, RandomZoom, Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "width = 256\n",
    "height = 256\n",
    "model_name = 'v2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model(width, height):\n",
    "    model = Sequential([\n",
    "        # preprocessing layers \n",
    "        Rescaling(1./255, input_shape=(width, height, 1)),\n",
    "        RandomRotation(0.2),\n",
    "        RandomZoom(0.2, 0.2),\n",
    "        # convolutional layers\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool1'),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool2'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "        MaxPooling2D(pool_size=(2, 2), name='maxpool3'),\n",
    "        Flatten(name='flatten'),\n",
    "        Dense(128, activation='relu', name='dense1'),\n",
    "        Dropout(0.5, name='dropout'),\n",
    "        Dense(2, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data_training/training\"\n",
    "validation_dir = \"./data_training/validation\"\n",
    "\n",
    "def train_model(model, batch_size, width, height, epochs, model_name, initial_epoch=0, log_dir=None):\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        './data_training/training',\n",
    "        image_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "    validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        './data_training/validation',\n",
    "        image_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        color_mode='grayscale')\n",
    "\n",
    "    # Use the existing log directory if provided, else create a new one\n",
    "    if not log_dir:\n",
    "        log_dir = f\"logs/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}_{model_name}\"\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1, write_images=True)\n",
    "    checkpoint_path = f\"{model_name}_{{epoch:02d}}.weights.h5\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, save_weights_only=True, save_freq='epoch')\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        initial_epoch=initial_epoch,\n",
    "        validation_data=validation_ds,\n",
    "        callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkubicek/repos/charging-station-monitor/.env/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:18: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-05-04 07:15:49.739127: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-05-04 07:15:49.739153: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 128.00 GB\n",
      "2024-05-04 07:15:49.739157: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 48.00 GB\n",
      "2024-05-04 07:15:49.739173: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-04 07:15:49.739184: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/mkubicek/repos/charging-station-monitor/.env/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88442 files belonging to 2 classes.\n",
      "Found 4026 files belonging to 2 classes.\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 07:15:52.295148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 75ms/step - accuracy: 0.9821 - loss: 0.0509 - val_accuracy: 0.9853 - val_loss: 0.0471\n",
      "Epoch 34/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 79ms/step - accuracy: 0.9820 - loss: 0.0523 - val_accuracy: 0.9903 - val_loss: 0.0405\n",
      "Epoch 35/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 75ms/step - accuracy: 0.9830 - loss: 0.0476 - val_accuracy: 0.9896 - val_loss: 0.0471\n",
      "Epoch 36/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 75ms/step - accuracy: 0.9837 - loss: 0.0479 - val_accuracy: 0.9851 - val_loss: 0.0421\n",
      "Epoch 37/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 75ms/step - accuracy: 0.9831 - loss: 0.0502 - val_accuracy: 0.9886 - val_loss: 0.0557\n",
      "Epoch 38/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 75ms/step - accuracy: 0.9837 - loss: 0.0473 - val_accuracy: 0.9883 - val_loss: 0.0440\n",
      "Epoch 39/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 75ms/step - accuracy: 0.9836 - loss: 0.0482 - val_accuracy: 0.9888 - val_loss: 0.0638\n",
      "Epoch 40/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 75ms/step - accuracy: 0.9849 - loss: 0.0468 - val_accuracy: 0.9903 - val_loss: 0.0449\n",
      "Epoch 41/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 76ms/step - accuracy: 0.9848 - loss: 0.0453 - val_accuracy: 0.9923 - val_loss: 0.0421\n",
      "Epoch 42/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 76ms/step - accuracy: 0.9854 - loss: 0.0430 - val_accuracy: 0.9908 - val_loss: 0.0501\n",
      "Epoch 43/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 74ms/step - accuracy: 0.9851 - loss: 0.0430 - val_accuracy: 0.9911 - val_loss: 0.0421\n",
      "Epoch 44/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 73ms/step - accuracy: 0.9852 - loss: 0.0442 - val_accuracy: 0.9923 - val_loss: 0.0319\n",
      "Epoch 45/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 72ms/step - accuracy: 0.9853 - loss: 0.0456 - val_accuracy: 0.9916 - val_loss: 0.0433\n",
      "Epoch 46/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 72ms/step - accuracy: 0.9851 - loss: 0.0451 - val_accuracy: 0.9913 - val_loss: 0.0435\n",
      "Epoch 47/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 72ms/step - accuracy: 0.9855 - loss: 0.0426 - val_accuracy: 0.9955 - val_loss: 0.0229\n",
      "Epoch 48/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 72ms/step - accuracy: 0.9845 - loss: 0.0468 - val_accuracy: 0.9893 - val_loss: 0.0459\n",
      "Epoch 49/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 72ms/step - accuracy: 0.9866 - loss: 0.0406 - val_accuracy: 0.9911 - val_loss: 0.0397\n",
      "Epoch 50/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 73ms/step - accuracy: 0.9860 - loss: 0.0430 - val_accuracy: 0.9945 - val_loss: 0.0347\n",
      "Epoch 51/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 74ms/step - accuracy: 0.9857 - loss: 0.0421 - val_accuracy: 0.9933 - val_loss: 0.0405\n",
      "Epoch 52/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 75ms/step - accuracy: 0.9859 - loss: 0.0412 - val_accuracy: 0.9938 - val_loss: 0.0289\n",
      "Epoch 53/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 75ms/step - accuracy: 0.9866 - loss: 0.0411 - val_accuracy: 0.9925 - val_loss: 0.0358\n",
      "Epoch 54/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 74ms/step - accuracy: 0.9856 - loss: 0.0450 - val_accuracy: 0.9814 - val_loss: 0.0934\n",
      "Epoch 55/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 74ms/step - accuracy: 0.9862 - loss: 0.0402 - val_accuracy: 0.9846 - val_loss: 0.0690\n",
      "Epoch 56/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 75ms/step - accuracy: 0.9870 - loss: 0.0398 - val_accuracy: 0.9650 - val_loss: 0.2434\n",
      "Epoch 57/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 74ms/step - accuracy: 0.9856 - loss: 0.0459 - val_accuracy: 0.9866 - val_loss: 0.0669\n",
      "Epoch 58/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 80ms/step - accuracy: 0.9865 - loss: 0.0416 - val_accuracy: 0.9901 - val_loss: 0.0375\n",
      "Epoch 59/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 81ms/step - accuracy: 0.9871 - loss: 0.0382 - val_accuracy: 0.9858 - val_loss: 0.0712\n",
      "Epoch 60/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 78ms/step - accuracy: 0.9870 - loss: 0.0393 - val_accuracy: 0.9764 - val_loss: 0.0902\n",
      "Epoch 61/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 77ms/step - accuracy: 0.9870 - loss: 0.0396 - val_accuracy: 0.9896 - val_loss: 0.0363\n",
      "Epoch 62/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 78ms/step - accuracy: 0.9876 - loss: 0.0383 - val_accuracy: 0.9834 - val_loss: 0.0634\n",
      "Epoch 63/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 78ms/step - accuracy: 0.9877 - loss: 0.0386 - val_accuracy: 0.9824 - val_loss: 0.1038\n",
      "Epoch 64/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 86ms/step - accuracy: 0.9869 - loss: 0.0382 - val_accuracy: 0.9908 - val_loss: 0.0678\n",
      "Epoch 65/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 77ms/step - accuracy: 0.9874 - loss: 0.0400 - val_accuracy: 0.9841 - val_loss: 0.1287\n",
      "Epoch 66/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 80ms/step - accuracy: 0.9875 - loss: 0.0381 - val_accuracy: 0.9871 - val_loss: 0.0991\n",
      "Epoch 67/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 81ms/step - accuracy: 0.9874 - loss: 0.0394 - val_accuracy: 0.9878 - val_loss: 0.0472\n",
      "Epoch 68/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 79ms/step - accuracy: 0.9875 - loss: 0.0391 - val_accuracy: 0.9749 - val_loss: 0.1411\n",
      "Epoch 69/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 79ms/step - accuracy: 0.9875 - loss: 0.0389 - val_accuracy: 0.9866 - val_loss: 0.0610\n",
      "Epoch 70/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 78ms/step - accuracy: 0.9875 - loss: 0.0377 - val_accuracy: 0.9891 - val_loss: 0.0712\n",
      "Epoch 71/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 82ms/step - accuracy: 0.9874 - loss: 0.0391 - val_accuracy: 0.9769 - val_loss: 0.2437\n",
      "Epoch 72/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 94ms/step - accuracy: 0.9867 - loss: 0.0415 - val_accuracy: 0.9846 - val_loss: 0.1536\n",
      "Epoch 73/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 88ms/step - accuracy: 0.9878 - loss: 0.0379 - val_accuracy: 0.9861 - val_loss: 0.1174\n",
      "Epoch 74/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 86ms/step - accuracy: 0.9871 - loss: 0.0401 - val_accuracy: 0.9886 - val_loss: 0.0645\n",
      "Epoch 75/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 89ms/step - accuracy: 0.9885 - loss: 0.0366 - val_accuracy: 0.9764 - val_loss: 0.1066\n",
      "Epoch 76/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 92ms/step - accuracy: 0.9877 - loss: 0.0386 - val_accuracy: 0.9806 - val_loss: 0.2026\n",
      "Epoch 77/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 89ms/step - accuracy: 0.9878 - loss: 0.0370 - val_accuracy: 0.9856 - val_loss: 0.0949\n",
      "Epoch 78/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 82ms/step - accuracy: 0.9872 - loss: 0.0377 - val_accuracy: 0.9821 - val_loss: 0.2360\n",
      "Epoch 79/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 79ms/step - accuracy: 0.9877 - loss: 0.0377 - val_accuracy: 0.9774 - val_loss: 0.2175\n",
      "Epoch 80/100\n",
      "\u001b[1m2764/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 78ms/step - accuracy: 0.9875 - loss: 0.0403 - val_accuracy: 0.9856 - val_loss: 0.1228\n",
      "Epoch 81/100\n",
      "\u001b[1m2375/2764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.9888 - loss: 0.0356"
     ]
    }
   ],
   "source": [
    "# Load the existing model and weights\n",
    "model = get_new_model(width, height)\n",
    "\n",
    "# Resume training\n",
    "checkpoint_file = 'v2.h5_32.weights.h5'\n",
    "model.load_weights(checkpoint_file)\n",
    "existing_log_dir = \"logs/20240503-233657_v2.h5\"\n",
    "#existing_log_dir = None\n",
    "initial_epoch = 32\n",
    "\n",
    "model, history = train_model(model, batch_size=32, width=width, height=height, epochs=epochs, model_name=model_name, initial_epoch=initial_epoch, log_dir=existing_log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
